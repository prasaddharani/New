import os
import fitz  # PyMuPDF
from PIL import Image
import io
import re
from openai import OpenAI
from typing import List, Tuple, Dict

# Set your OpenAI API key
os.environ["OPENAI_API_KEY"] = "your_openai_api_key_here"
client = OpenAI()

class PDFContent:
    def __init__(self, text: str, page_num: int):
        self.text = text
        self.page_num = page_num

def extract_content_and_images(pdf_path: str) -> Tuple[List[PDFContent], Dict[str, Image.Image]]:
    doc = fitz.open(pdf_path)
    content = []
    images = {}
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        
        # Extract text
        text = page.get_text()
        content.append(PDFContent(text, page_num + 1))
        
        # Extract images and their tags
        img_list = page.get_images(full=True)
        for img_index, img in enumerate(img_list):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image = Image.open(io.BytesIO(image_bytes))
            
            # Find the corresponding "Fig: image_name" tag
            matches = re.findall(r"Fig: ([\w\-]+)", text)
            if matches:
                image_tag = matches[img_index] if img_index < len(matches) else f"unnamed_image_{page_num}_{img_index}"
                images[image_tag] = image
    
    return content, images

def generate_answer(query: str, content: List[PDFContent]) -> str:
    context = "\n\n".join([f"Page {item.page_num}:\n{item.text}" for item in content])
    
    prompt = f"""You are an AI assistant that answers questions based on a user manual. 
    Use the following context to answer the question. If you can't answer the question based on the context, say "I don't have enough information to answer that question."
    If there are relevant images, mention their tags in the format "Fig: image_name".

    Context:
    {context}

    Question: {query}

    Answer:"""

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ],
        temperature=0,
        max_tokens=300
    )

    return response.choices[0].message.content

def answer_question(question: str, content: List[PDFContent], images: Dict[str, Image.Image]) -> Tuple[str, List[Image.Image]]:
    answer = generate_answer(question, content)
    
    # Extract mentioned image tags from the answer
    mentioned_tags = re.findall(r"Fig: ([\w\-]+)", answer)
    relevant_images = [images[tag] for tag in mentioned_tags if tag in images]
    
    return answer, relevant_images

# Main execution
pdf_path = "path_to_your_user_manual.pdf"
content, images = extract_content_and_images(pdf_path)

while True:
    question = input("Ask a question about the user manual (or type 'quit' to exit): ")
    if question.lower() == 'quit':
        break
    
    answer, relevant_images = answer_question(question, content, images)
    print(f"Answer: {answer}")
    
    if relevant_images:
        print(f"Found {len(relevant_images)} related images. Displaying...")
        for i, image in enumerate(relevant_images):
            image.show()
            print(f"Image {i+1} displayed.")
    else:
        print("No related images found.")
